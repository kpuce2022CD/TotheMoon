import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import re
import urllib.request
import os
from konlpy.tag import Okt
from tqdm import tqdm
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

from tensorflow.keras.layers import Embedding, Dense, LSTM
from tensorflow.keras.models import Sequential
from tensorflow.keras.models import load_model
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
import pickle


os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

okt = Okt()
f = open("stopwords.txt", 'r' , encoding='utf8')
stopwords = f.read()
# ì •ìˆ˜ ì¸ì½”ë”©

max_len = 30

# loading
with open('tokenizer.pickle', 'rb') as handle:
    tokenizer = pickle.load(handle)


loaded_model = load_model('best_model.h5')

def comment_classify(comment_file):
  print("dd")

def sentiment_predict(new_sentence):
  new_sentence = re.sub(r'[^ã„±-ã…ã…-ã…£ê°€-í£ ]','', new_sentence)
  new_sentence = okt.morphs(new_sentence, stem=True) # í† í°í™”
  new_sentence = [word for word in new_sentence if not word in stopwords] # ë¶ˆìš©ì–´ ì œê±°
  encoded = tokenizer.texts_to_sequences([new_sentence]) # ì •ìˆ˜ ì¸ì½”ë”©
  pad_new = pad_sequences(encoded, maxlen = max_len) # íŒ¨ë”©
  score = float(loaded_model.predict(pad_new)) # ì˜ˆì¸¡
  if(score > 0.5):
    print("{:.2f}% í™•ë¥ ë¡œ ê¸ì • ë¦¬ë·°ì…ë‹ˆë‹¤.\n".format(score * 100))
  else:
    print("{:.2f}% í™•ë¥ ë¡œ ë¶€ì • ë¦¬ë·°ì…ë‹ˆë‹¤.\n".format((1 - score) * 100))

#ì´ëª¨í‹°ì½˜ ì œê±° í•¨ìˆ˜(ASCII ì½”ë“œì— í•´ë‹¹í•˜ì§€ ì•ŠëŠ” ê²½ìš°)
def remove_emoji(inputString):
    return inputString.encode('ascii', 'ignore').decode('ascii')

# ì´ëª¨í‹°ì½˜ ìœ ë‹ˆì½”ë“œ íŒ¨í„´
emoji_pattern = re.compile("["
                               u"\U0001F600-\U0001F64F"  # emoticons
                               u"\U0001F300-\U0001F5FF"  # symbols & pictographs
                               u"\U0001F680-\U0001F6FF"  # transport & map symbols
                               u"\U0001F1E0-\U0001F1FF"  # flags (iOS)
                               u"\U00002500-\U00002BEF"  # chinese char
                               u"\U00002702-\U000027B0"
                               u"\U00002702-\U000027B0"
                               #u"\U000024C2-\U0001F251"
                               u"\U0001f926-\U0001f937"
                               u"\U00010000-\U0010ffff"
                               u"\u2640-\u2642"
                               u"\u2600-\u2B55"
                               u"\u200d"
                               u"\u23cf"
                               u"\u23e9"
                               u"\u231a"
                               u"\ufe0f"  # dingbats
                               u"\u3030"
                               "]+", flags=re.UNICODE)

#ì´ëª¨í‹°ì½˜ ë¬¸ìë¡œ ëŒ€ì²´ 
def emoticonToWord(comment):        
    emoticon_list = ["â¤ï¸","â¤","ğŸ§¡","ğŸ’›","ğŸ’š","ğŸ’™","ğŸ’","ğŸ’“","ğŸ’œ","â£ï¸","ğŸ’•","ğŸ’˜","ğŸ’—","ğŸ’“","ğŸ’","ğŸ’Ÿ","ğŸ˜»","ğŸ’”","ğŸ‘","ğŸ‘","ğŸ™Œ","ğŸ˜˜","ğŸ˜","ğŸ˜ƒ","ğŸ˜„","ğŸ˜","ğŸ˜†","â˜ºï¸","ğŸ˜Š","ğŸ˜š","ğŸ¤—","ğŸ˜­","ğŸ˜¢","ğŸ˜¤","ğŸ˜ ","ğŸ˜¡","ğŸ¤¬","ğŸ˜³","ğŸ¤”","ğŸ¤£","ğŸ¥°","ğŸ¤¢","ğŸ¥³"]
    emotion_list = [" ì‚¬ë‘í•´ìš”"," ì‚¬ë‘í•´ìš”"," ì‚¬ë‘í•´ìš”"," ì‚¬ë‘í•´ìš”"," ì‚¬ë‘í•´ìš”"," ì‚¬ë‘í•´ìš”"," ì‚¬ë‘í•´ìš”"," ì‚¬ë‘í•´ìš”"," ì‚¬ë‘í•´ìš”"," ì‚¬ë‘í•´ìš”"," ì‚¬ë‘í•´ìš”"," ì‚¬ë‘í•´ìš”"," ì‚¬ë‘í•´ìš”"," ì‚¬ë‘í•´ìš”"," ì‚¬ë‘í•´ìš”"," ì‚¬ë‘í•´ìš”"," ì‚¬ë‘í•´ìš”"," ì‹«ì–´í•´ìš”"," ìµœê³ ì—ìš”","ìµœì•…ì´ì—ìš”","ë§Œì„¸"," ì‚¬ë‘í•´ìš”"," ì‚¬ë‘í•´ìš”"," ì¢‹ì•„ìš”"," ì¢‹ì•„ìš”"," ì¢‹ì•„ìš”"," ì¢‹ì•„ìš”"," ì¢‹ì•„ìš”"," ì¢‹ì•„ìš”"," ì¢‹ì•„ìš”"," ì¢‹ì•„ìš”"," ìŠ¬í¼ìš”"," ìŠ¬í¼ìš”"," ì‚ì¡Œì–´ìš”"," í™”ë‚¬ì–´ìš”"," í™”ë‚¬ì–´ìš”"," í™”ë‚¬ì–´ìš”"," ì˜ ëª¨ë¥´ê² ì–´ìš”"," ê³ ë¯¼í•´ ë³¼ê²Œìš”"," ì¢‹ì•„ìš”"," ì¢‹ì•„ìš”"," ì—­ê²¨ì›Œìš”"," ì¶•í•˜í•´ìš”"]
    emodic = dict(zip(emoticon_list,emotion_list))  
    templist = list(comment)   #ìˆ˜ì •ì„ ìœ„í•´ì„œ ì„ì‹œë¡œ ë¬¸ì¥-> ë¦¬ìŠ¤íŠ¸
    
    for index ,word in enumerate(comment):
        if word in emoticon_list:   # ì •ì˜í•œ ì´ëª¨í‹°ì½˜ë¦¬ìŠ¤íŠ¸ì— ìˆë‹¤ë©´
            temp = word.replace(word, emodic[word])  #í•´ë‹¹ ì´ëª¨í‹°ì½˜ì„ ì„¤ì •í•œ ë‹¨ì–´ë¡œ ë³€í™˜
            templist[index] = temp
    comment = "".join(templist)        #ë¦¬ìŠ¤íŠ¸ -> ë¬¸ì¥
    return comment

# ìœ íŠœë¸Œ ë°ì´í„° ì „ì²˜ë¦¬
def youtube_comment_processing(filename) :
    df = pd.read_excel(filename)
    comment_dic = {}  # ì¶”ì¶œí•œ ëŒ“ê¸€ ë°ì´í„°
    author_dic = {} # ì¶”ì¶œí•œ ì‘ì„±ì ë°ì´í„°
    date_dic = {} # ì¶”ì¶œí•œ ì‘ì„± ë‚ ì§œ ë°ì´í„°
    num_likes_dic = {} # ì¶”ì¶œí•œ ì¢‹ì•„ìš” ê°œìˆ˜ ë°ì´í„°
    comment_result = []  # ì „ì²˜ë¦¬ í›„ ë°ì´í„°
    author_result = []  # ì „ì²˜ë¦¬ í›„ ë°ì´í„°
    date_result = []  # ì „ì²˜ë¦¬ í›„ ë°ì´í„°
    num_likes_result = []  # ì „ì²˜ë¦¬ í›„ ë°ì´í„°

    # ì—‘ì…€ íŒŒì¼ë¡œë¶€í„° ë°ì´í„° ì¶”ì¶œ
    for i in df.index:
        comment = df.loc[i, 'comment']  # ëŒ“ê¸€ ë‚´ìš©
        author = df.loc[i, 'author']  # ì‘ì„±ì
        date = df.loc[i, 'date']  # ì‘ì„± ë‚ ì§œ
        num_likes = df.loc[i, 'num_likes']  # ì¢‹ì•„ìš” ê°œìˆ˜
        comment_dic[i] = comment  # comment_dic ë”•ì…”ë„ˆë¦¬ì— ì¶”ê°€
        author_dic[i] = author # author_dic ë”•ì…”ë„ˆë¦¬ì— ì¶”ê°€
        date_dic[i] = date # date_dic ë”•ì…”ë„ˆë¦¬ì— ì¶”ê°€
        num_likes_dic[i] = num_likes # num_likes ë”•ì…”ë„ˆë¦¬ì— ì¶”ê°€


    for val in comment_dic.values() :
        print(val) # ëŒ“ê¸€ ì›ë³¸
        val = emoticonToWord(val)      #ì´ëª¨í‹°ì½˜ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        val = re.sub(emoji_pattern, "", val) # ì´ëª¨í‹°ì½˜ ì œê±°
        #remove_emoji(val) #ì´ëª¨í‹°ì½˜ ì œê±°
        val = re.sub("<br>|â¤|ğŸ§¡|ğŸ’›|ğŸ’š|ğŸ’™|ğŸ’œ|ğŸ¤|ğŸ–¤|ğŸ¤|ğŸ’”|â£|ğŸ’•|ğŸ’|ğŸ’“|ğŸ’—|ğŸ’–|ğŸ’˜|ğŸ’|ğŸ’Ÿ", " ", val) # <br> í•œì¤„ë„ê¸° -> ìŠ¤í˜ì´ìŠ¤ ê³µë°±ìœ¼ë¡œ ë³€í™˜ , ì œê±° ì´ëª¨í‹°ì½˜ ì¶”ê°€
        comment_result.append(val)

    for val in author_dic.values() : # ì‘ì„±ì ë°°ì—´ì— ì¶”ê°€
        author_result.append(val)

    for val in date_dic.values() : # ì‘ì„± ë‚ ì§œ ë°°ì—´ì— ì¶”ê°€
        date_result.append(val)

    for val in num_likes_dic.values() : # ì¢‹ì•„ìš” ê°œìˆ˜ ë°°ì—´ì— ì¶”ê°€
        num_likes_result.append(val)

    for i in range(len(comment_result)): #ë°°ì—´ í¬ê¸°ë§Œí¼ ì‹¤í–‰
        print("------------------ì „ì²˜ë¦¬ í›„-----------------")
        print("ëŒ“ê¸€: "+comment_result[i])
        print("ì‘ì„±ì: "+author_result[i])
        print("ì‘ì„± ë‚ ì§œ: "+date_result[i])
        print("ì¢‹ì•„ìš” ê°œìˆ˜: "+str(num_likes_result[i]))
        sentiment_predict(comment_result[i])

youtube_comment_processing("QE-f163l7L4.xlsx")