import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import re
import urllib.request
import os
from konlpy.tag import Okt
from tqdm import tqdm
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

from tensorflow.keras.layers import Embedding, Dense, LSTM
from tensorflow.keras.models import Sequential
from tensorflow.keras.models import load_model
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
import pickle

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

okt = Okt()
f = open("stopwords.txt", 'r', encoding='utf8')
stopwords = f.read()
# ì •ìˆ˜ ì¸ì½”ë”©

max_len = 30

# loading
with open('np_tokenizer.pickle', 'rb') as handle:
    tokenizer = pickle.load(handle)

loaded_model = load_model('np_classify_model.h5')


def comment_classify(comment_file):
    print("dd")


def sentiment_predict(new_sentence):
    new_sentence = re.sub(r'[^ã„±-ã…ã…-ã…£ê°€-í£ ]', '', new_sentence)
    new_sentence = okt.morphs(new_sentence, stem=True)  # í† í°í™”
    new_sentence = [word for word in new_sentence if not word in stopwords]  # ë¶ˆìš©ì–´ ì œê±°
    encoded = tokenizer.texts_to_sequences([new_sentence])  # ì •ìˆ˜ ì¸ì½”ë”©
    pad_new = pad_sequences(encoded, maxlen=max_len)  # íŒ¨ë”©
    score = float(loaded_model.predict(pad_new))  # ì˜ˆì¸¡
    return score

# ì´ëª¨í‹°ì½˜ ì œê±° í•¨ìˆ˜(ASCII ì½”ë“œì— í•´ë‹¹í•˜ì§€ ì•ŠëŠ” ê²½ìš°)
def remove_emoji(inputString):
    return inputString.encode('ascii', 'ignore').decode('ascii')


# ì´ëª¨í‹°ì½˜ ìœ ë‹ˆì½”ë“œ íŒ¨í„´
emoji_pattern = re.compile("["
                           u"\U0001F600-\U0001F64F"  # emoticons
                           u"\U0001F300-\U0001F5FF"  # symbols & pictographs
                           u"\U0001F680-\U0001F6FF"  # transport & map symbols
                           u"\U0001F1E0-\U0001F1FF"  # flags (iOS)
                           u"\U00002500-\U00002BEF"  # chinese char
                           u"\U00002702-\U000027B0"
                           u"\U00002702-\U000027B0"
                           # u"\U000024C2-\U0001F251"
                           u"\U0001f926-\U0001f937"
                           u"\U00010000-\U0010ffff"
                           u"\u2640-\u2642"
                           u"\u2600-\u2B55"
                           u"\u200d"
                           u"\u23cf"
                           u"\u23e9"
                           u"\u231a"
                           u"\ufe0f"  # dingbats
                           u"\u3030"
                           "]+", flags=re.UNICODE)


# ì´ëª¨í‹°ì½˜ ë¬¸ìë¡œ ëŒ€ì²´
def emoticonToWord(comment):
    emoticon_list = ["â¤ï¸", "â¤", "ğŸ§¡", "ğŸ’›", "ğŸ’š", "ğŸ’™", "ğŸ’", "ğŸ’“", "ğŸ’œ", "â£ï¸", "ğŸ’•", "ğŸ’˜", "ğŸ’—", "ğŸ’“", "ğŸ’", "ğŸ’Ÿ",
                     "ğŸ˜»", "ğŸ’”", "ğŸ‘", "ğŸ‘", "ğŸ™Œ", "ğŸ˜˜", "ğŸ˜", "ğŸ˜ƒ", "ğŸ˜„", "ğŸ˜", "ğŸ˜†", "â˜ºï¸", "ğŸ˜Š", "ğŸ˜š", "ğŸ¤—", "ğŸ˜­",
                     "ğŸ˜¢", "ğŸ˜¤", "ğŸ˜ ", "ğŸ˜¡", "ğŸ¤¬", "ğŸ˜³", "ğŸ¤”", "ğŸ¤£", "ğŸ¥°", "ğŸ¤¢", "ğŸ¥³"]
    emotion_list = [" ì‚¬ë‘í•´ìš”", " ì‚¬ë‘í•´ìš”", " ì‚¬ë‘í•´ìš”", " ì‚¬ë‘í•´ìš”", " ì‚¬ë‘í•´ìš”", " ì‚¬ë‘í•´ìš”", " ì‚¬ë‘í•´ìš”", " ì‚¬ë‘í•´ìš”", " ì‚¬ë‘í•´ìš”", " ì‚¬ë‘í•´ìš”", " ì‚¬ë‘í•´ìš”",
                    " ì‚¬ë‘í•´ìš”", " ì‚¬ë‘í•´ìš”", " ì‚¬ë‘í•´ìš”", " ì‚¬ë‘í•´ìš”", " ì‚¬ë‘í•´ìš”", " ì‚¬ë‘í•´ìš”", " ì‹«ì–´í•´ìš”", " ìµœê³ ì—ìš”", "ìµœì•…ì´ì—ìš”", "ë§Œì„¸", " ì‚¬ë‘í•´ìš”",
                    " ì‚¬ë‘í•´ìš”", " ì¢‹ì•„ìš”", " ì¢‹ì•„ìš”", " ì¢‹ì•„ìš”", " ì¢‹ì•„ìš”", " ì¢‹ì•„ìš”", " ì¢‹ì•„ìš”", " ì¢‹ì•„ìš”", " ì¢‹ì•„ìš”", " ìŠ¬í¼ìš”", " ìŠ¬í¼ìš”", " ì‚ì¡Œì–´ìš”",
                    " í™”ë‚¬ì–´ìš”", " í™”ë‚¬ì–´ìš”", " í™”ë‚¬ì–´ìš”", " ì˜ ëª¨ë¥´ê² ì–´ìš”", " ê³ ë¯¼í•´ ë³¼ê²Œìš”", " ì¢‹ì•„ìš”", " ì¢‹ì•„ìš”", " ì—­ê²¨ì›Œìš”", " ì¶•í•˜í•´ìš”"]
    emodic = dict(zip(emoticon_list, emotion_list))
    templist = list(comment)  # ìˆ˜ì •ì„ ìœ„í•´ì„œ ì„ì‹œë¡œ ë¬¸ì¥-> ë¦¬ìŠ¤íŠ¸

    for index, word in enumerate(comment):
        if word in emoticon_list:  # ì •ì˜í•œ ì´ëª¨í‹°ì½˜ë¦¬ìŠ¤íŠ¸ì— ìˆë‹¤ë©´
            temp = word.replace(word, emodic[word])  # í•´ë‹¹ ì´ëª¨í‹°ì½˜ì„ ì„¤ì •í•œ ë‹¨ì–´ë¡œ ë³€í™˜
            templist[index] = temp
    comment = "".join(templist)  # ë¦¬ìŠ¤íŠ¸ -> ë¬¸ì¥
    return comment


# ìœ íŠœë¸Œ ë°ì´í„° ì „ì²˜ë¦¬
def youtube_comment_processing(filename):
    df = pd.read_excel(filename)

    comments = df.values    # ëŒ“ê¸€ ë°ì´í„°(ëŒ“ê¸€, ì‘ì„±ì, ë‚ ì§œ, ì¢‹ì•„ìš” ìˆ˜)
    comment_result = []  # ì „ì²˜ë¦¬ í›„ ë°ì´í„°
    dic_return = [] # ìŠ¤í”„ë§ìœ¼ë¡œ ì „ì†¡í•  json ë°ì´í„°

    for i in comments:
        val = i[0]
        print(val)
        val = re.sub("<br>", " ", val)  # <br> í•œì¤„ë„ê¸° -> ìŠ¤í˜ì´ìŠ¤ ê³µë°±ìœ¼ë¡œ ë³€í™˜ , ì œê±° ì´ëª¨í‹°ì½˜ ì¶”ê°€
        val = emoticonToWord(val)  # ì´ëª¨í‹°ì½˜ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        val = re.sub(emoji_pattern, "", val)  # ì´ëª¨í‹°ì½˜ ì œê±°
        remove_emoji(val) #ì´ëª¨í‹°ì½˜ ì œê±°
        comment_result.append(val)

    for i in range(len(comment_result)):  # ë°°ì—´ í¬ê¸°ë§Œí¼ ì‹¤í–‰
        print("------------------ì „ì²˜ë¦¬ í›„-----------------")
        print("ëŒ“ê¸€: " + comments[i][0])
        print("ì‘ì„±ì: " + comments[i][1])
        print("ì‘ì„± ë‚ ì§œ: " + comments[i][2])
        print("ì¢‹ì•„ìš” ê°œìˆ˜: " + str(comments[i][3]))
        score = sentiment_predict(comment_result[i])
        if (score > 0.5):
            if(score > 0.8):
                print("{:.2f}% í™•ë¥ ë¡œ ê¸ì • ë¦¬ë·°ì…ë‹ˆë‹¤.\n".format(score * 100))
                dic_temp = {"index": "1", "id": comments[i][1], "comment": comments[i][0],
                            "date": comments[i][2], "num_like": str(comments[i][3])}
                dic_return.append(dic_temp)
        else:
            if(score < 0.2):
                print("{:.2f}% í™•ë¥ ë¡œ ë¶€ì • ë¦¬ë·°ì…ë‹ˆë‹¤.\n".format((1 - score) * 100))
                dic_temp = {"index": "0", "id": comments[i][1], "comment": comments[i][0],
                            "date": comments[i][2], "num_like": str(comments[i][3])}
                dic_return.append(dic_temp)

    return dic_return

##test